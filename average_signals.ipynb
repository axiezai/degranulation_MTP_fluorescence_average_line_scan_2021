{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import natsort\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some signal averaging for Mitchell\n",
    "\n",
    "## Load files first\n",
    "The example data files are all placed in `data` folder, write a function to create a list of files in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(pattern):\n",
    "    \"\"\"\n",
    "    Extracts file in alphanumerical order that match the provided pattern\n",
    "    \"\"\"\n",
    "    if isinstance(pattern, list):\n",
    "        pattern = os.path.join(*pattern)\n",
    "        \n",
    "    files = natsort.natsorted(glob.glob(pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError('Pattern could not detect file(s)')\n",
    "        \n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs Cell:\n",
    "\n",
    "Place your path to input and output directories in `\" \"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'    # Replace data with relative path to new folder like I mentioned before\n",
    "output_dir = 'outputs'    # same replacement for outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load as `DataFrames`, mag or magenta should work now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data_files = get_files(data_dir + '/*.csv')\n",
    "print('There are {} data csv files'.format(len(data_files)))\n",
    "\n",
    "# split into cyan, yellow, magenta\n",
    "cyan_data = [val for val in data_files if re.search(r'cyan\\.csv', val)]\n",
    "yellow_data = [val for val in data_files if re.search(r'yellow\\.csv', val)]\n",
    "magenta_data = [val for val in data_files if re.search(r'(mag|magenta)\\.csv', val)]\n",
    "\n",
    "# sanity check to make sure they are the same number of files\n",
    "assert len(cyan_data)==len(yellow_data)==len(magenta_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create channel specific dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyan = pd.concat((pd.read_csv(f, usecols=['Value']) for f in cyan_data), axis = 1).fillna(0)\n",
    "df_yellow = pd.concat((pd.read_csv(f, usecols=['Value']) for f in yellow_data), axis = 1).fillna(0)\n",
    "df_magenta = pd.concat((pd.read_csv(f, usecols=['Value']) for f in magenta_data), axis = 1).fillna(0)\n",
    "\n",
    "df_cyan.columns = np.arange(df_cyan.shape[1])\n",
    "df_yellow.columns = np.arange(df_yellow.shape[1])\n",
    "df_magenta.columns = np.arange(df_magenta.shape[1])\n",
    "# show example:\n",
    "df_magenta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 3 Nx56 dataframes that are actually usable ... not stupid `.csv` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Center around max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find which signal had the smallest number of pixels drawn, use this as standard length\n",
    "shortest_cyan = np.argmax((df_cyan == 0).astype(int).sum(axis=0).values)\n",
    "shortest_yellow = np.argmax((df_yellow == 0).astype(int).sum(axis=0).values)\n",
    "shortest_magenta = np.argmax((df_magenta == 0).astype(int).sum(axis=0).values)\n",
    "print('Shortest length of cyan is at column {}'.format(shortest_cyan))\n",
    "print('Shortest length of yellow is at column {}'.format(shortest_yellow))\n",
    "print('Shortest length of magenta is at column {}'.format(shortest_magenta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('File 19 is {}'.format(cyan_data[shortest_cyan]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like `_9_4_cyan.csv` is the one with the shortest line! Now we need to find where this guy's maximum is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cyan maximum is at index {}'.format(np.argmax(df_cyan.iloc[:,19].values)))\n",
    "cyan_shortest_viz = df_cyan.iloc[:,19].values\n",
    "plt.plot(np.ma.masked_equal(cyan_shortest_viz, 0))\n",
    "plt.vlines(np.argmax(cyan_shortest_viz), ymin= 288, ymax = 430, linestyles = 'dashed', colors = 'r') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write a function to realign the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realign_data(in_data):\n",
    "    \"\"\"\n",
    "    Center data around maximum of shortest column, pad with 0's \n",
    "    \n",
    "    Returns:\n",
    "        d - new dataframe with realigned data\n",
    "        shifts - how each entry was shifted\n",
    "    \"\"\"\n",
    "    x, y = in_data.shape\n",
    "    d = pd.DataFrame(0, index=np.arange(x), columns = np.arange(y))\n",
    "    shifts = np.zeros(y)\n",
    "    \n",
    "    # Find longest length sample and find it's peak\n",
    "    ind_longest = np.argmin((in_data == 0).astype(int).sum(axis=0).values)\n",
    "    peak_longest = np.argmax(in_data.loc[:, ind_longest].values)\n",
    "    \n",
    "    # arrange the rest of the data's peaks into the new dataframe lining up to longest peak\n",
    "    for column in in_data:\n",
    "        peak = np.argmax(in_data[column].values)\n",
    "        pdiff = peak_longest - peak\n",
    "        d[column] = in_data[column].shift(periods=pdiff, fill_value=0)\n",
    "        assert np.argmax(d[column]) == peak_longest\n",
    "        shifts[column] = pdiff\n",
    "    return d, shifts\n",
    "\n",
    "def shift_data(in_data, shifts):\n",
    "    \"\"\"\n",
    "    Shift dataframe columns based on input reference shifts\n",
    "    \n",
    "    Returns:\n",
    "        d - new shifted dataframe\n",
    "    \"\"\"\n",
    "    x, y = in_data.shape\n",
    "    d = pd.DataFrame(0, index=np.arange(x), columns = np.arange(y))\n",
    "    ind_shifts = shifts.astype(int)\n",
    "    for column in in_data:\n",
    "        d[column] = in_data[column].shift(periods=ind_shifts[column], fill_value=0)\n",
    "        \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the averaged aligned curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "cyan_aligned, shifts = realign_data(df_cyan)\n",
    "yellow_aligned = shift_data(df_yellow, shifts)\n",
    "magenta_aligned = shift_data(df_magenta, shifts)\n",
    "\n",
    "ave_cyan = np.zeros(cyan_aligned.shape[0])\n",
    "ave_yellow = np.zeros(yellow_aligned.shape[0])\n",
    "ave_magenta = np.zeros(magenta_aligned.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in cyan_aligned.iterrows():\n",
    "    #vec = cyan_aligned.loc[index,:].values\n",
    "    val = row[row != 0]\n",
    "    ave_cyan[index] = np.mean(val)\n",
    "\n",
    "for column, vals in cyan_aligned.iteritems():\n",
    "    event_ind = cyan_aligned.index[cyan_aligned[column]!=0].tolist()\n",
    "    cyan_aligned.loc[event_ind, column] = minmax_scale(cyan_aligned.loc[event_ind,column].values)\n",
    "plt.plot(minmax_scale(ave_cyan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in yellow_aligned.iterrows():\n",
    "    val = row[row!=0]\n",
    "    ave_yellow[index] = np.mean(val)\n",
    "\n",
    "for column, vals in yellow_aligned.iteritems():\n",
    "    event_ind = yellow_aligned.index[yellow_aligned[column]!=0].tolist()\n",
    "    yellow_aligned.loc[event_ind, column] = minmax_scale(yellow_aligned.loc[event_ind,column].values)\n",
    "    \n",
    "plt.plot(minmax_scale(ave_yellow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in magenta_aligned.iterrows():\n",
    "    val = row[row!=0]\n",
    "    ave_magenta[index] = np.mean(val)\n",
    "\n",
    "for column, vals in magenta_aligned.iteritems():\n",
    "    event_ind = magenta_aligned.index[magenta_aligned[column]!=0].tolist()\n",
    "    magenta_aligned.loc[event_ind, column] = minmax_scale(magenta_aligned.loc[event_ind,column].values)\n",
    "    \n",
    "plt.plot(minmax_scale(ave_magenta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(minmax_scale(ave_cyan), c='c')\n",
    "ax.plot(minmax_scale(ave_yellow), c='y')\n",
    "ax.plot(minmax_scale(ave_magenta), c='m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as `outputs/.csv` \n",
    "\n",
    "Save the averages as 1 `csv` file where each column is a color. And save each individual colors as separate `csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example_average = pd.DataFrame({'cyan': minmax_scale(ave_cyan),\n",
    "                                   'yellow': minmax_scale(ave_yellow),\n",
    "                                   'magenta': minmax_scale(ave_magenta)})\n",
    "df_example_average.to_csv(output_dir+'/averages.csv', index = False)\n",
    "cyan_aligned.to_csv(output_dir+'/cyan_data.csv', index=False)\n",
    "yellow_aligned.to_csv(output_dir+'/yellow_data.csv', index=False)\n",
    "magenta_aligned.to_csv(output_dir+'/magenta_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_py3",
   "language": "python",
   "name": "image_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
